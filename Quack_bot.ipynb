{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from twitterscraper.query import query_tweets_from_user\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import pyphen\n",
    "from twython import Twython\n",
    "import tweepy\n",
    "import json\n",
    "from auth import (\n",
    "    consumer_key,\n",
    "    consumer_secret,\n",
    "    access_token,\n",
    "    access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current tweet: @saradietschy @johnhilltube TikTok actually seems to dump views on creators who are returning from a break. Not say… https://t.co/FzC6Inm6Nz \n",
      "\n",
      "penultimate tweet: @TessaViolet Every day since 2010??? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    target_user = 'hankgreen'\n",
    "    tweet_count = 10\n",
    "    #tweepy setup\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
    "    \n",
    "    tweets = tweepy.Cursor(api.user_timeline,id=target_user).items(tweet_count)\n",
    "    tweets_list = [[tweet.created_at, tweet.id, tweet.text] for tweet in tweets]\n",
    "    \n",
    "    current_tweet = tweets_list[0][2]\n",
    "    penultimate_tweet = tweets_list[1][2]\n",
    "    \n",
    "    # print(\"current tweet:\", current_tweet, \"\\n\")\n",
    "    # print(\"penultimate tweet:\", penultimate_tweet, \"\\n\")\n",
    "    tweet_state = 'tweet_output.json'\n",
    " \n",
    "    #print the retrieved tweets to the screen:\n",
    "    #for single_tweet in list_of_tweets:\n",
    "    #print(single_tweet.text, single_tweet.timestamp, \"\\n\") '''\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "former tweets: \n",
      "\n",
      "tweet[0]: @saradietschy @johnhilltube TikTok actually seems to dump views on creators who are returning from a break. Not say… https://t.co/FzC6Inm6Nz \n",
      "\n",
      "tweet[1]: @TessaViolet Every day since 2010??? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "    former_tweet_zero = \"\"\n",
    "    former_tweet_one = \"\"\n",
    "    try:    \n",
    "        with open(tweet_state) as json_file:\n",
    "            former_tweets = json.load(json_file)\n",
    "            for t in former_tweets['tweets']:\n",
    "                print('former tweets:','\\n')\n",
    "                former_tweet_zero = t['tweet_zero']\n",
    "                former_tweet_one = t['tweet_one']\n",
    "    except:\n",
    "        print('error in opening former tweets in', tweet_state)\n",
    "    finally:\n",
    "        print('tweet[0]:', former_tweet_zero, \"\\n\")\n",
    "        print('tweet[1]:', former_tweet_one, \"\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quacked(tweet):\n",
    "    split_tweet = tweet.split()\n",
    "    #print(split_tweet)\n",
    "    quacked_tweet_array = []\n",
    "    exception_words = [\"a\", \"an\" \"or\", \"the\", \"and\", \"in\", \"at\", \"some\", \"all\"]\n",
    "    pyphen.language_fallback('nl_NL_variant1')\n",
    "    dic = pyphen.Pyphen(lang='nl_NL')\n",
    "    \n",
    "    #iterate over each word in tweet\n",
    "    for word in split_tweet:\n",
    "        punctuation = ''\n",
    "        punctuation_split = re.findall(r\"[\\w']+|[.,!?;]\", word)\n",
    "        #print(punctuation_split)\n",
    "        quacked_word = dic.inserted(word)\n",
    "        \n",
    "        # handle weblinks \n",
    "        if 'http' in word: \n",
    "            quacked_word = \" \" + word    \n",
    "        elif word in exception_words:\n",
    "            quacked_word = word\n",
    "        elif len(punctuation_split) > 1:\n",
    "            word = punctuation_split[0]\n",
    "            punctuation = punctuation_split[1:]\n",
    "            punctuation = \"\".join(punctuation)\n",
    "            if word.isupper():\n",
    "                quacked_word = 'Quack'\n",
    "            else:\n",
    "                quacked_word = 'quack'\n",
    "            #print('punctuation separated')\n",
    "      #if words are multi-syllabic, replace the first syllable   \n",
    "        elif '-' in quacked_word:\n",
    "            quacked_split_word = quacked_word.split(\"-\")\n",
    "            if quacked_split_word[0][0].isupper():\n",
    "                quacked_split_word[0] = 'Quack'\n",
    "            else:\n",
    "                quacked_split_word[0] = 'quack'\n",
    "            quacked_word = \"\".join(quacked_split_word)  \n",
    "        else:\n",
    "            if quacked_word[0].isupper():\n",
    "                quacked_word = 'Quack'\n",
    "            else:\n",
    "                quacked_word = 'quack'\n",
    "                \n",
    "        # add quacked word to new array\n",
    "        if punctuation != '':\n",
    "            quacked_word = quacked_word + punctuation\n",
    "        #print(word)\n",
    "        #print(quacked_word)\n",
    "        if quacked_word != '':\n",
    "            quacked_tweet_array.append(quacked_word)\n",
    "        #print(quacked_tweet_array)\n",
    "        \n",
    "    #join array to make new string\n",
    "    quacked_tweet = \" \".join(quacked_tweet_array)\n",
    "    # print(quacked_tweet)\n",
    "    return quacked_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet(text):\n",
    "    twitter = Twython(\n",
    "        consumer_key,\n",
    "        consumer_secret,\n",
    "        access_token,\n",
    "        access_token_secret\n",
    "    )    \n",
    "    message = text\n",
    "    \n",
    "    if len(text) > 280:\n",
    "        tweet_textA = '1/2 ' + message[0:131] + '...'\n",
    "        tweet_textB = '2/2 ...' + message[131:]\n",
    "        twitter.update_status(status=tweet_textA)\n",
    "        time.sleep(7)\n",
    "        twitter.update_status(status=tweet_textB)\n",
    "        print('message too long: split into two tweets:\\nTweet Text A: ' + tweet_textA + '\\nTweet Text B: ', tweet_textB)\n",
    "        \n",
    "    else:\n",
    "        twitter.update_status(status=message)\n",
    "        print(\"Message tweeted: %s\" % message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no change\n",
      "exit program\n",
      "End Program\n"
     ]
    }
   ],
   "source": [
    "if (current_tweet == former_tweet_zero) & (penultimate_tweet == former_tweet_one):\n",
    "        print(\"no change\")\n",
    "        print('exit program')\n",
    "        pass\n",
    "elif (current_tweet == former_tweet_zero) & (penultimate_tweet != former_tweet_one): \n",
    "    print(\"change detected in penultimate tweet, pinned tweet likely\")\n",
    "       \n",
    "        #send tweet\n",
    "    quacked_tweet = quacked(penultimate_tweet)\n",
    "    tweet(quacked_tweet)\n",
    "\n",
    "        #save new tweet to persistent storage:\n",
    "    current_tweets_object = {}\n",
    "    current_tweets_object['tweets'] = []\n",
    "    current_tweets_object['tweets'].append({\n",
    "        'tweet_zero': current_tweet,\n",
    "        'tweet_one': penultimate_tweet \n",
    "    })\n",
    "    try:\n",
    "        with open(tweet_state, 'w') as json_file:\n",
    "            #file.write(current_tweet)\n",
    "            json.dump(current_tweets_object, json_file)\n",
    "            print(\"current tweets saved: Current tweet: \", current_tweet, \"\\nPenultimate tweet: \", penultimate_tweet)\n",
    "    except:\n",
    "        print('error saving ', tweet_state)\n",
    "else:\n",
    "    print(\"Change detected\")\n",
    "\n",
    "        #send tweet\n",
    "    quacked_tweet = quacked(current_tweet)\n",
    "    tweet(quacked_tweet)\n",
    "\n",
    "        #save new tweet to persistent storage:\n",
    "    current_tweets_object = {}\n",
    "    current_tweets_object['tweets'] = []\n",
    "    current_tweets_object['tweets'].append({\n",
    "        'tweet_zero': current_tweet,\n",
    "        'tweet_one': penultimate_tweet \n",
    "    })\n",
    "    try: \n",
    "        with open(tweet_state, 'w') as json_file:\n",
    "            json.dump(current_tweets_object, json_file)\n",
    "            print(\"Current tweets saved: Current tweet: \", current_tweet, \"\\nPenultimate tweet: \", penultimate_tweet)\n",
    "    except:\n",
    "        print('error saving ', tweet_state)    \n",
    "print('End Program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
