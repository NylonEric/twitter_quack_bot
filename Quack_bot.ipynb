{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "from twitterscraper.query import query_tweets_from_user\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pyphen\n",
    "from twython import Twython\n",
    "import json\n",
    "from auth import (\n",
    "    consumer_key,\n",
    "    consumer_secret,\n",
    "    access_token,\n",
    "    access_token_secret\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    target_user = 'hankgreen'\n",
    "    list_of_tweets = query_tweets_from_user(target_user, 10)\n",
    "    current_tweet = list_of_tweets[0].text\n",
    "    penultimate_tweet = list_of_tweets[1].text\n",
    "    \n",
    "    print(\"current tweet:\", current_tweet, \"\\n\")\n",
    "    tweet_state = 'tweet_output.json'\n",
    " \n",
    "    #print the retrieved tweets to the screen:\n",
    "    for tweet in list_of_tweets:\n",
    "        print(tweet.text, tweet.timestamp, \"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(tweet_state) as json_file:\n",
    "        former_tweets = json.load(json_file)\n",
    "        for t in former_tweets['tweets']:\n",
    "            print('former tweets:','\\n')\n",
    "            former_tweet_zero = t['tweet_zero']\n",
    "            former_tweet_one = t['tweet_one']\n",
    "            print('tweet[0]:', former_tweet_zero, \"\\n\")\n",
    "            print('tweet[1]:', former_tweet_one, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quacked(tweet):\n",
    "    split_tweet = tweet.split()\n",
    "    print(split_tweet)\n",
    "    quacked_tweet_array = []\n",
    "    \n",
    "    pyphen.language_fallback('nl_NL_variant1')\n",
    "    dic = pyphen.Pyphen(lang='nl_NL')\n",
    "    \n",
    "    #iterate over each word in tweet\n",
    "    for word in split_tweet:\n",
    "        punctuation = ''\n",
    "        punctuation_split = re.findall(r\"[\\w']+|[.,!?;]\", word)\n",
    "        print(punctuation_split)\n",
    "        quacked_word = dic.inserted(word)\n",
    "        \n",
    "        # remove weblinks \n",
    "        if 'http' in word: \n",
    "            quacked_word = ''\n",
    "            print('weblink removed')\n",
    "        \n",
    "        elif len(punctuation_split) > 1:\n",
    "            word = punctuation_split[0]\n",
    "            punctuation = punctuation_split[1:]\n",
    "            punctuation = \"\".join(punctuation)\n",
    "            if word.isupper():\n",
    "                quacked_word = 'Quack'\n",
    "            else:\n",
    "                quacked_word = 'quack'\n",
    "            print('punctuation separated')\n",
    "      #if words are multi-syllabic, replace the first syllable   \n",
    "        elif '-' in quacked_word:\n",
    "            quacked_split_word = quacked_word.split(\"-\")\n",
    "            if quacked_split_word[0][0].isupper():\n",
    "                quacked_split_word[0] = 'Quack'\n",
    "            else:\n",
    "                quacked_split_word[0] = 'quack'\n",
    "            quacked_word = \"\".join(quacked_split_word)  \n",
    "        else:\n",
    "            if quacked_word[0].isupper():\n",
    "                quacked_word = 'Quack'\n",
    "            else:\n",
    "                quacked_word = 'quack'\n",
    "                \n",
    "        # add quacked word to new array\n",
    "        if punctuation != '':\n",
    "            quacked_word = quacked_word + punctuation\n",
    "        print(word)\n",
    "        print(quacked_word)\n",
    "        if quacked_word != '':\n",
    "            quacked_tweet_array.append(quacked_word)\n",
    "        print(quacked_tweet_array)\n",
    "        \n",
    "    #join array to make new string\n",
    "    quacked_tweet = \" \".join(quacked_tweet_array)\n",
    "    \n",
    "    return quacked_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet(text):\n",
    "    twitter = Twython(\n",
    "        consumer_key,\n",
    "        consumer_secret,\n",
    "        access_token,\n",
    "        access_token_secret\n",
    "    )    \n",
    "    message = text\n",
    "    print(message)\n",
    "    #twitter.update_status(status=message)\n",
    "    print(\"Tweeted: %s\" % message)\n",
    "    print(twitter)\n",
    "\n",
    "    if len(text) > 280:\n",
    "        tweet_textA = '1/2 ' + message[0:131] + '...'\n",
    "        tweet_textB = '2/2 ...' + message[131:]\n",
    "        twitter.update_status(status=tweet_textA)\n",
    "        time.sleep(7)\n",
    "        twitter.update_status(status=tweet_textB)\n",
    "        print('message too long: split into two tweets: ' + tweet_textA + '\\n', tweet_textB)\n",
    "        \n",
    "    else:\n",
    "        twitter.update_status(status=message)\n",
    "        print('message tweeted: ', message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (current_tweet == former_tweet_zero) & (penultimate_tweet == former_tweet_one):\n",
    "        print(\"no change\")\n",
    "        print('exit program')\n",
    "        pass\n",
    "elif (current_tweet == former_tweet_zero) & (penultimate_tweet != former_tweet_one): \n",
    "    print(\"change detected in penultimate tweet, pinned tweet likely\")\n",
    "       \n",
    "        #send tweet\n",
    "    quacked_tweet = quacked(penultimate_tweet)\n",
    "    print(quacked_tweet)\n",
    "    tweet(quacked_tweet)\n",
    "        #save new tweet to persistent storage:\n",
    "    \n",
    "    current_tweets_object = {}\n",
    "    current_tweets_object['tweets'] = []\n",
    "    current_tweets_object['tweets'].append({\n",
    "        'tweet_zero': current_tweet,\n",
    "        'tweet_one': penultimate_tweet \n",
    "    })\n",
    "    with open(tweet_state, 'w') as json_file:\n",
    "        #file.write(current_tweet)\n",
    "        json.dump(current_tweets_object, json_file)\n",
    "        print(\"current tweets saved:\", current_tweet, penultimate_tweet)\n",
    "else:\n",
    "    print(\"Change detected\")\n",
    "    quacked_tweet = quacked(current_tweet)\n",
    "    print(quacked_tweet)\n",
    "    tweet(quacked_tweet)\n",
    "    #save new tweet to persistent storage:\n",
    "    \n",
    "    current_tweets_object = {}\n",
    "    current_tweets_object['tweets'] = []\n",
    "    current_tweets_object['tweets'].append({\n",
    "        'tweet_zero': current_tweet,\n",
    "        'tweet_one': penultimate_tweet \n",
    "    })\n",
    "    with open(tweet_state, 'w') as json_file:\n",
    "        json.dump(current_tweets_object, json_file)\n",
    "        print(\"current tweets saved:\", current_tweet, penultimate_tweet)\n",
    "        \n",
    "print('End Program')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
